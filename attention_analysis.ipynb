{"cells":[{"cell_type":"markdown","source":["# Setup #"],"metadata":{"id":"RZnfbkzDqR4Y"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31368,"status":"ok","timestamp":1681696011428,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"LgdnTgKWRXsN","outputId":"f3e93d66-4181-4bc1-da73-616d8b86405f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CPT\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/CPT"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/CPT\n","# !cp base_model.py setformer.py transformer.py dataset.py utils.py lamb.py make_stats.py baselines.py data_utils.py plot.py ../Covariant-Particle-Transformer\n","!git remote set-url origin https://shikaiqiu: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@github.com/shikaiqiu/Covariant-Particle-Transformer.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_EAexLn-N2j","executionInfo":{"status":"ok","timestamp":1681680943842,"user_tz":240,"elapsed":6,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"}},"outputId":"dac2ceb0-942c-46f8-b422-9169c9d5289c"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CPT\n"]}]},{"cell_type":"code","source":["# ! git add base_model.py setformer.py transformer.py dataset.py utils.py lamb.py\n","# ! git add make_stats.py baselines.py data_utils.py plot.py\n","!git add attention_an\n","! git commit -am \"upload files\"\n","! git push\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKwx-cc06X53","outputId":"da77f08f-f693-4b26-92ae-45716d820e61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: pathspec 'attention' did not match any files\n"]}]},{"cell_type":"code","source":["! scp shikai_q@gauss.orie.cornell.edu:/home/shikai_q/x ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBa818ZT7SWr","executionInfo":{"status":"ok","timestamp":1681679825295,"user_tz":240,"elapsed":1173,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"}},"outputId":"aa583f9c-325e-452d-81ba-606e666ddc6a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Host key verification failed.\r\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4p9BtQ4SKWu"},"outputs":[],"source":["! pip uninstall torch-scatter torch-sparse\n","! pip install --no-cache-dir torch-scatter -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","! pip install --no-cache-dir torch-sparse -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","! pip install torch-geometric==1.7.2\n","! pip install lmdb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHBC0MrmQv4J"},"outputs":[],"source":["import os\n","import random\n","import os.path as osp\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch_geometric.data import Dataset, Data, DataLoader\n","from torch.utils.data import ConcatDataset, ChainDataset\n","from pathlib import Path as Path\n","from dataset import *\n","from utils import *\n","from setformer import *\n","from lamb import Lamb\n","from functools import partial\n","from tqdm import tqdm\n","# import wandb\n","tqdm = partial(tqdm, position=0, leave=True)\n","import matplotlib.pylab as pylab\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","USE_GPU = True\n","dtype = torch.float32 # we will be using float\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print('using device:', device)\n","\n","from seaborn import heatmap\n","import seaborn as sns\n","sns.set_style(\"white\")\n","sns.axes_style(\"white\")"]},{"cell_type":"markdown","source":["# Load model (trained on ttH) #"],"metadata":{"id":"3TcOYu4oqZHM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uc9j9-qC1X0o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679939747213,"user_tz":240,"elapsed":26240,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"}},"outputId":"9c3192ee-fd92-4f5a-ce43-b86247853f44"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using Lamb optimizer with lr=0.0001\n","INFO:train_logger:Using Lamb optimizer with lr=0.0001\n","Loaded model from ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/saved_models/min_val_loss_model.pt\n","INFO:train_logger:Loaded model from ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/saved_models/min_val_loss_model.pt\n","Model has 12M parameters\n","INFO:train_logger:Model has 12M parameters\n","Loaded model from ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/saved_models/min_val_loss_model.pt\n","INFO:train_logger:Loaded model from ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/saved_models/min_val_loss_model.pt\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["### DON'T CHANGE ###\n","max_num_output = 2\n","base_dir = './trained'\n","arch = 'CovariantTopFormer'\n","model_params = {\n","    'geometric': True,\n","    'break_eta_covariance': False,\n","    'in_dim': 9,\n","    'out_dim': 4,\n","    'max_num_output': max_num_output,\n","    'hidden_dim': 256,\n","    'num_convs': (6, 6),\n","    'heads': 4,\n","    'mass': 173,\n","    'match_scale_factor': torch.FloatTensor([0, 1, 1, 0]), # used for matching dR = (dy, dphi)    \n","    'p_norm': 2, # used in matching and loss\n","    'beta': 0.8,\n","    'dropout': 0.,\n","    'schedule_lr': False,\n","    'use_gpu': USE_GPU,\n","    'uniform_attention': False,\n","}\n","tag = '0901_ttH'\n","output_dir = f\"{arch}_{model_params['num_convs']}_{model_params['hidden_dim']}_{tag}\"\n","output_dir = os.path.join(base_dir, output_dir)\n","model_params['output_dir'] = output_dir\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","model = eval(arch)(**model_params).to(device)\n","model.load('min_val_loss_model.pt')\n","### DON'T CHANGE ###"]},{"cell_type":"markdown","source":["# Load dataset (ttH, ttW, or ttbar) #\n","(the model is trained on ttH, so the last two test generalization to different processes)"],"metadata":{"id":"B054uVHsqM7S"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2349,"status":"ok","timestamp":1679940664485,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"-Oq6gA5mZRPv","outputId":"ef97474b-cccf-4dc6-b70c-0f34580da1d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Padding up to 2 outputs\n","X: (pT, y, phi, m)\n","Y: (pT, y, phi, m)\n"]}],"source":["### DON'T CHANGE ###\n","max_num_output = 2 # assert that there are at most two tops\n","detector_x = True # use cartesian coordinates for input\n","detector_y = True # use cartesian coordinates for output\n","to_torch_test = get_to_torch(max_num_output, detector_x=detector_x, detector_y=detector_y, test=True) # reformat the data for torch\n","### DON'T CHANGE ###\n","\n","# Pick a dataset by uncommenting it\n","\n","# ttH\n","dataset_names = ['data/final/ttH']\n","Ds = [ConcatDataset([LMDBDataset(f'{dataset_name}/data_{i}', transform=to_torch_test, use_cache=False, readahead=False) for i in range(0, 10)]) for dataset_name in dataset_names]\n","Ds = [split_dataset(D, name=ds_name, max_train_event=None, max_test_event=None) for D, ds_name in zip(Ds, dataset_names)]\n","D_train = ConcatDataset([D[0] for D in Ds])\n","D_val = ConcatDataset([D[1] for D in Ds])\n","D_test = ConcatDataset([D[2] for D in Ds])\n","\n","# # ttW\n","# dataset_names = ['data/final/ttW']\n","# D_test = LMDBDataset(f'{dataset_names[0]}/data_0', transform=to_torch_test, use_cache=True, readahead=False)\n","\n","# # ttbar\n","# dataset_names = ['data/final/ttbar']\n","# D_test = LMDBDataset(f'{dataset_names[0]}/data_0', transform=to_torch_test, use_cache=True, readahead=False)"]},{"cell_type":"markdown","source":["# Run inference #"],"metadata":{"id":"C72E2pYDqbsG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1662696,"status":"ok","timestamp":1679942564721,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"sSTQSaTarWAq","outputId":"b872df56-f50a-4ac7-a2a5-2b84a0f84e05"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"," 56%|█████▌    | 5000/9001 [29:55<23:56,  2.78it/s]\n","Saved test result at ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/test_result_ttH_attn_j_only.pt\n","INFO:train_logger:Saved test result at ./trained/CovariantTopFormer_(6, 6)_256_0901_ttH/test_result_ttH_attn_j_only.pt\n"]}],"source":["# Can skip to next cell to use precomputed test results\n","batch_size = 128\n","max_num_batch = 5000 # set a large value (1e7) to run on all test data\n","version_name = \"ttH_attn_j_only\" # choose a name for saving result to disk\n","\n","test_loader = DataLoader(D_test, batch_size, num_workers=4, prefetch_factor=1, follow_batch=['x_in']) if D_test else None\n","test_result = model.run_inference(test_loader, max_num_batch=max_num_batch, force_correct_num_pred=True, version=version_name)\n","# model.run_inference contains code to extract attention weights and\n","# infer if any triplet associated with a top matches the 3 objects with highest attention weights from that top (attention matching)"]},{"cell_type":"code","source":["am = test_result['attention_matched'] == 1\n","tm = test_result['truth_matched'] == 1\n","am[tm].mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzMt7dfO0AXR","executionInfo":{"status":"ok","timestamp":1679944096668,"user_tz":240,"elapsed":321,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"}},"outputId":"7a62d493-d491-4cfc-90dc-f5b9deefb6c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6350448230217066"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["# Make table and plots #"],"metadata":{"id":"h0KPFC2MqenH"}},{"cell_type":"code","source":["from make_stats import run as make_plots_and_tables\n","output_dir = './trained/CovariantTopFormer_(6, 6)_256_0901_ttH'\n","### DON'T CHANGE ###\n","max_num_output = 2 # assert that there are at most two tops\n","bins = 2 # bins - 1 = actual number of bins...\n","entries_per_bin = 100000000 # for binning the result in phase space. set a large number to skip this.\n","### DON'T CHANGE ###\n","\n","\n","version_name = 'attn_j_only' # Choose from {ttH_final, ttW_final, ttbar_final} to use precomputed test results\n","test_result = torch.load(f'{output_dir}/test_result_{version_name}.pt')\n","make_plots_and_tables(test_result, f'{output_dir}/test_result_{version_name}', max_num_output, bins, entries_per_bin) \n","# once the above run, can find a summary table named result.csv inside the output directory (2nd arg). E.g: 3rd column shows attention matching efficency."],"metadata":{"id":"1WajOQB-lb7Z","executionInfo":{"status":"ok","timestamp":1679899346670,"user_tz":240,"elapsed":71821,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"}},"colab":{"base_uri":"https://localhost:8080/","height":894},"outputId":"e4ead314-1d9c-4b40-ab40-b4d4f8bf3c84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","dataset: ttH\n","cut: Inclusive\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/numpy/lib/function_base.py:4486: RuntimeWarning: invalid value encountered in subtract\n","  diff_b_a = subtract(b, a)\n","100%|██████████| 1/1 [00:00<00:00, 68.63it/s]\n","/content/drive/MyDrive/CPT/make_stats.py:352: RuntimeWarning: invalid value encountered in true_divide\n","  chi2s_pred_alt.append((dy_pred_alt / pred_alt_error) ** 2)\n"]},{"output_type":"stream","name":"stdout","text":["cut: Truth-matched\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 128.13it/s]\n","100%|██████████| 1/1 [00:00<00:00, 193.70it/s]\n","/usr/local/lib/python3.9/dist-packages/numpy/lib/nanfunctions.py:1560: RuntimeWarning: All-NaN slice encountered\n","  r, k = function_base._ureduce(a,\n","/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_axes.py:6762: RuntimeWarning: All-NaN slice encountered\n","  xmin = min(xmin, np.nanmin(xi))\n","/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_axes.py:6763: RuntimeWarning: All-NaN slice encountered\n","  xmax = max(xmax, np.nanmax(xi))\n","/usr/local/lib/python3.9/dist-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in true_divide\n","  return n/db/n.sum(), bin_edges\n","/content/drive/MyDrive/CPT/make_stats.py:591: RuntimeWarning: invalid value encountered in double_scalars\n","  pT_resolution = iqr(pT_ratio) / np.median(pT_ratio)\n"]},{"output_type":"stream","name":"stdout","text":["cut: Not truth-matched\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 94.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cut: Attention-matched\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 229.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cut: Hadronic\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 110.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cut: Leptonic\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 150.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n","Applied trigger cut\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Additional plots (available in overleaf) #"],"metadata":{"id":"uTbaO45KqhSe"}},{"cell_type":"markdown","source":["Two interesting findings so far:\n","1. Across three processes, triplet attention (sum attention over truth triplets) weakly correlates (0.1 for ttH, 0.3~0.4 for ttbar and ttW) with low prediction error but much less so (< 0.1) if we condition on the top being correctly attention matched. This means the model relies on identifying the triplets for good predictions to some extent but also uses additional info in the events.\n","2. For events from unseen processes (ttW and ttbar), triplet attention correlates much more strongly with low prediction error. This makes sense because for unseen processes, the only reliable way to predict the top is by reconstructing it. In constrast, in ttH events, the model learns to also use make use of diphoton info to predict the top."],"metadata":{"id":"PfQr4obvtCAG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhU45Fey5seP"},"outputs":[],"source":["# output_dir = ''\n","error = test_result['pred_errors']\n","attn = test_result['triplet_attn']\n","kl = test_result['KL']\n","n = test_result['N_object']\n","tm = test_result['truth_matched'] == 1\n","am = test_result['attention_matched'] == 1\n","\n","plt.figure(dpi=200)\n","plt.scatter(attn[am], error[am], s=0.25, label=f'correlation={np.corrcoef(attn[am], error[am])[0,1]:.2f}')\n","plt.xlabel('Triplet attention')\n","plt.ylabel('Scaled L2 error')\n","plt.legend()\n","# plt.savefig(f'{output_dir}/triplet_attn_vs_error_am.png')\n","\n","plt.figure(dpi=200)\n","plt.scatter(attn[tm], error[tm], s=0.25, label=f'correlation={np.corrcoef(attn[tm], error[tm])[0,1]:.2f}')\n","plt.xlabel('Triplet attention')\n","plt.ylabel('Scaled L2 error')\n","plt.legend()\n","# plt.savefig(f'{output_dir}/triplet_attn_vs_error_tm.png')\n","\n","plt.figure(dpi=200)\n","plt.hist(attn[tm], bins=40, density=True, histtype='step', label='Truth matched')\n","plt.hist(attn[am], bins=40, density=True, histtype='step', label='Attention matched')\n","plt.xlabel('Triplet attention')\n","plt.ylabel('Normalized to unity')\n","plt.legend()\n","# plt.savefig(f'{output_dir}/triplet_attn.png')\n","\n","plt.figure(dpi=200)\n","plt.hist(kl[np.logical_not(tm)], bins=40, density=True, histtype='step', label='Unmatched')\n","plt.hist(kl[tm], bins=40, density=True, histtype='step', label='Truth matched')\n","plt.hist(kl[am], bins=40, density=True, histtype='step', label='Attention matched')\n","plt.xlabel(r'$KL(\\alpha||uniform)$')\n","plt.ylabel('Normalized to unity')\n","plt.legend()\n","# plt.savefig(f'{output_dir}/kl.png')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}