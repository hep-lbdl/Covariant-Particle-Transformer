{"cells":[{"cell_type":"markdown","metadata":{"id":"RZnfbkzDqR4Y"},"source":["# Setup #"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHBC0MrmQv4J"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","import torch\n","from torch_geometric.data import DataLoader\n","from torch.utils.data import ConcatDataset\n","from pathlib import Path as Path\n","from dataset import *\n","from utils import *\n","from cpt import *\n","from functools import partial\n","from tqdm import tqdm\n","import wandb\n","tqdm = partial(tqdm, position=0, leave=True)\n","import matplotlib.pylab as pylab\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","USE_GPU = True\n","dtype = torch.float32 # we will be using float\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print('using device:', device)\n","\n","from seaborn import heatmap\n","import seaborn as sns\n","sns.set_style(\"white\")\n","sns.axes_style(\"white\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Load datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_names = ['data/final/ttH']\n","max_num_output = 2\n","detector_x = True\n","detector_y = True\n","to_torch = get_to_torch(max_num_output, detector_x=detector_x, detector_y=detector_y)\n","to_torch_test = get_to_torch(max_num_output, detector_x=detector_x, detector_y=detector_y, test=True)\n","Ds = [ConcatDataset([LMDBDataset(f'{dataset_name}/data_{i}', transform=to_torch, use_cache=False, readahead=False) for i in range(0, 10)]) for dataset_name in dataset_names]\n","Ds = [split_dataset(D, name=ds_name, max_train_event=None, max_test_event=None) for D, ds_name in zip(Ds, dataset_names)]\n","D_train = ConcatDataset([D[0] for D in Ds])\n","D_val = ConcatDataset([D[1] for D in Ds])\n","D_test = ConcatDataset([D[2] for D in Ds])\n","batch_size = 256\n","train_loader = DataLoader(D_train, batch_size, num_workers=0, shuffle=True)\n","val_loader = DataLoader(D_val, batch_size, num_workers=0) if D_val else None\n","test_loader = DataLoader(D_test, batch_size, num_workers=0) if D_test else None"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3TcOYu4oqZHM"},"source":["# Train model #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26240,"status":"ok","timestamp":1679939747213,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"uc9j9-qC1X0o","outputId":"9c3192ee-fd92-4f5a-ce43-b86247853f44"},"outputs":[],"source":["max_num_output = 2 # assert that there are at most ${max_num_output} tops\n","base_dir = './trained'\n","arch = 'CovariantTopFormer'\n","model_params = {\n","    'geometric': True,\n","    'break_eta_covariance': False,\n","    'in_dim': 9,\n","    'out_dim': 4,\n","    'max_num_output': max_num_output,\n","    'hidden_dim': 256,\n","    'num_convs': (6, 6),\n","    'heads': 4,\n","    'mass': 173,\n","    'match_scale_factor': torch.FloatTensor([0, 1, 1, 0]), # used for matching dR = (dy, dphi)    \n","    'p_norm': 2, # used in matching and loss\n","    'beta': 0.8, # loss weight for predicting number of tops\n","    'dropout': 0.,\n","    'schedule_lr': False,\n","    'use_gpu': USE_GPU,\n","    'uniform_attention': False,\n","}\n","tag = 'TEST' # CHANGE THIS\n","output_dir = f\"{arch}_{model_params['num_convs']}_{model_params['hidden_dim']}_{tag}\"\n","output_dir = os.path.join(base_dir, output_dir)\n","model_params['output_dir'] = output_dir\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","model = eval(arch)(**model_params).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# uncomment line below to load from most recent checkpoint\n","# model.load('most_recent_epoch_model.pt') \n","with wandb.init(project='CPT', name=tag, config=model_params, resume=False):\n","  model.train_model(100, train_loader, val_loader, None)"]},{"cell_type":"markdown","metadata":{"id":"C72E2pYDqbsG"},"source":["# Run inference #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1662696,"status":"ok","timestamp":1679942564721,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"sSTQSaTarWAq","outputId":"b872df56-f50a-4ac7-a2a5-2b84a0f84e05"},"outputs":[],"source":["batch_size = 1024\n","max_num_batch = 100 # set a large value (1e7) to run on all test data\n","version_name = 'FIXME' # choose a name for saving result to disk\n","\n","test_loader = DataLoader(D_test, batch_size, num_workers=4, prefetch_factor=1, follow_batch=['x_in']) if D_test else None\n","test_result = model.run_inference(test_loader, max_num_batch=max_num_batch, force_correct_num_pred=True, version=version_name)"]},{"cell_type":"markdown","metadata":{"id":"h0KPFC2MqenH"},"source":["# Make table and plots #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":894},"executionInfo":{"elapsed":71821,"status":"ok","timestamp":1679899346670,"user":{"displayName":"Shikai Qiu","userId":"05224618489085399239"},"user_tz":240},"id":"1WajOQB-lb7Z","outputId":"e4ead314-1d9c-4b40-ab40-b4d4f8bf3c84"},"outputs":[],"source":["from make_stats import run as make_plots_and_tables\n","### DON'T CHANGE ###\n","bins = 2 # bins - 1 = actual number of bins...\n","entries_per_bin = 100000000 # for binning the result in phase space. set a large number to skip this.\n","### DON'T CHANGE ###\n","\n","version_name = 'FIXME' \n","test_result = torch.load(f'{output_dir}/test_result_{version_name}.pt')\n","make_plots_and_tables(test_result, f'{output_dir}/test_result_{version_name}', max_num_output, bins, entries_per_bin) \n","# once the above run, can find a summary table named result.csv inside the output directory (2nd arg)."]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
